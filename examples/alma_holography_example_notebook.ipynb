{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556919e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -e .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d68f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "import shutil\n",
    "import dask\n",
    "import requests\n",
    "import time\n",
    "import psutil\n",
    "\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "from astrohack import holog\n",
    "from astrohack.dio import extract_holog\n",
    "from astrohack.dio import load_hack_file\n",
    "from astrohack._utils._io import _make_ant_pnt_dict\n",
    "\n",
    "from dask.distributed import Client, LocalCluster\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (15, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049390dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def performance(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start = time.time()\n",
    "        func(*args, **kwargs)\n",
    "        stop = time.time()\n",
    "        print(\"Completion time: {}\".format(stop - start))\n",
    "    return wrapper\n",
    "\n",
    "def _open_holog(hack_file, ddi):   \n",
    "    ant_grid_data = {}\n",
    "    \n",
    "    ant_list =  [dir_name for dir_name in os.listdir(hack_file) if os.path.isdir(hack_file)]\n",
    "    for ant in ant_list:\n",
    "        ant_grid_data[int(ant)] = xr.open_zarr(\"{name}/{ant}/{ddi}\".format(name=hack_file, ant=ant, ddi=ddi) )\n",
    "        \n",
    "    return ant_grid_data\n",
    "\n",
    "def print_hack_file(hack):\n",
    "    for ddi in hack.keys():\n",
    "        for scan in hack[ddi].keys():\n",
    "            for ant in hack[ddi][scan].keys():\n",
    "                print(\"=\"*150)\n",
    "                print(\"\\t\\t\\t\\t\\t\\t\\tddi={ddi}\\tscan={scan}\\t ant={ant}\".format(ddi=ddi, scan =scan, ant=ant))\n",
    "                print(\"=\"*150)\n",
    "                print(\"{xds}\".format(xds=hack[ddi][scan][ant]))\n",
    "\n",
    "def print_hack_directory_struct(name):\n",
    "    for ddi in os.listdir(name):\n",
    "        if ddi.isnumeric():\n",
    "            print(ddi,\"/\")\n",
    "            for scan in os.listdir(\"{name}/{ddi}\".format(name=name, ddi=ddi)):\n",
    "                if os.path.isdir(\"{name}/{ddi}/{scan}/\".format(name=name, ddi=ddi, scan=scan)) == False:\n",
    "                    print(\"|---\", scan)\n",
    "                    pass\n",
    "                else:\n",
    "                    print(\"|---\", scan, \"/\")\n",
    "                    for ant in os.listdir(\"{name}/{ddi}/{scan}/\".format(name=name, ddi=ddi, scan=scan)):\n",
    "                        print(\"\\t|---\", ant, \"/\")\n",
    "                \n",
    "def get_max_memory_allocation():\n",
    "    memory_string = str(int((psutil.virtual_memory().total/1e9)/os.cpu_count()))\n",
    "    return \"\".join((memory_string, 'GB'))\n",
    "\n",
    "def get_example_data():\n",
    "    google_file_id = '1zpOtduyXtbh0wg0s5KWYuEMy7roGq92a'\n",
    "    output = 'alma_band3.calibrated.DV16.ms.tar'\n",
    "    path = \"/\".join((os.getcwd(), output))\n",
    "    \n",
    "    download_file_from_google_drive(\n",
    "        id=google_file_id,\n",
    "        destination=path\n",
    "    )\n",
    "\n",
    "    \n",
    "    tar = tarfile.open(path)\n",
    "    tar.extractall()\n",
    "    tar.close()\n",
    "    \n",
    "    os.remove(path)\n",
    "    \n",
    "    return path.split('.tar')[0]\n",
    "\n",
    "def download_file_from_google_drive(id, destination):\n",
    "    URL = \"https://docs.google.com/uc?export=download\"\n",
    "\n",
    "    session = requests.Session()\n",
    "\n",
    "    response = session.get(URL, params = { 'id' : id , 'confirm': 1 }, stream = True)\n",
    "    token = get_confirm_token(response)\n",
    "\n",
    "    if token:\n",
    "        params = { 'id' : id, 'confirm' : token }\n",
    "        response = session.get(URL, params = params, stream = True)\n",
    "\n",
    "    save_response_content(response, destination)    \n",
    "\n",
    "def get_confirm_token(response):\n",
    "    for key, value in response.cookies.items():\n",
    "        if key.startswith('download_warning'):\n",
    "            return value\n",
    "\n",
    "    return None\n",
    "\n",
    "def save_response_content(response, destination):\n",
    "    CHUNK_SIZE = 32768\n",
    "\n",
    "    with open(destination, \"wb\") as f:\n",
    "        for chunk in response.iter_content(CHUNK_SIZE):\n",
    "            if chunk: # filter out keep-alive new chunks\n",
    "                f.write(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e96dbf-b5fe-438e-913a-942cc70477ed",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Setup\n",
    "This data file is a subset of a larger band3, calibrated holography measurement. The file contains a single ddi, a single scan and only baselines containing antenna DV16."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbd1a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ms_name = get_example_data()\n",
    "#ms_name = '/users/jhoskins/fornax/Development/alma_band3.calibrated.DV16.ms'\n",
    "ms_name = '/users/jhoskins/fornax/Development/J1924-2914.ms.split.calibrated.SPW3'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f7a2ff-ffb7-4f75-8ebd-ffec8ed55bbc",
   "metadata": {},
   "source": [
    "Here we setup the Dask distributed client which will be used to add parallelism to our jobs. In this case, we will use a total of 6 workers with a single thread and 8Gb of memeory each. The dashboard link that is returned allows the user to monitor each jobs from the browser.\n",
    "\n",
    "![title](documentation/dask_dashboard.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2876e7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    client = Client('http://127.0.0.1:8787')\n",
    "\n",
    "except:\n",
    "    cluster = LocalCluster(\n",
    "        n_workers=6,\n",
    "        threads_per_worker=1,\n",
    "        memory_limit='8GB'\n",
    "    )\n",
    "\n",
    "    client = Client(cluster)\n",
    "        \n",
    "print(client.dashboard_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8697b10-e051-4279-a6f0-f390d172f138",
   "metadata": {},
   "source": [
    "This input format to the `extract_holog(...)` function is in the form of a nested dictionary. The structure is as follows:\n",
    "```yaml\n",
    "ddi: {\n",
    "    scan:{\n",
    "         'map':[mapping antenna list]\n",
    "         'ref':[reference antenna list]\n",
    "         }\n",
    "    }\n",
    "},\n",
    ".\n",
    ".\n",
    ".\n",
    "ddi_n: {\n",
    "    scan_n:{\n",
    "         'map':[mapping antenna list]\n",
    "         'ref':[reference antenna list]\n",
    "         }\n",
    "    }\n",
    "}\n",
    "```\n",
    "The above is the structure for the case of a single (ddi, scan_ but the format can support *n* cases of (ddi, scan). This is user provided information based on the specific holography run being processed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169d6e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "DA = [\n",
    "    'DA41', 'DA42', 'DA43', \n",
    "    'DA44', 'DA45', 'DA46', \n",
    "    'DA48', 'DA49', 'DA50', \n",
    "    'DA51', 'DA52', 'DA53', \n",
    "    'DA54', 'DA55', 'DA56', \n",
    "    'DA57', 'DA58', 'DA59'\n",
    "]\n",
    "DV = [\n",
    "    'DV02', 'DV03', 'DV04', \n",
    "    'DV11', 'DV12', 'DV13', \n",
    "    'DV14', 'DV15', 'DV16', \n",
    "    'DV17', 'DV18', 'DV19', \n",
    "    'DV20', 'DV21', 'DV22', \n",
    "    'DV23', 'DV24', 'DV25'\n",
    "] \n",
    "\n",
    "holog_obs_description = {\n",
    "    0:{\n",
    "        2:{\n",
    "            'map':DV,\n",
    "            'ref':DA\n",
    "        } \n",
    "    }\n",
    "}\n",
    "\n",
    "holog_obs_description = {0:{2:{'map':DV,'ref':DA}, 6:{'map':DV,'ref':DA}, 10:{'map':DV,'ref':DA},4:{'map':DA,'ref':DV}, 8:{'map':DA,'ref':DV}, 12:{'map':DA,'ref':DV}}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aaf5491-dfbf-49ea-9ddb-efa65f1f8a19",
   "metadata": {},
   "source": [
    "# Extract Holography Data\n",
    "\n",
    "The extraction of the holography data is done effectively by leveraging the Dask based parallelism and compiled code via numba jit functions. There are also optimizations done by extracting only the minimum subsets of data that are needed to build the output data structure which will be used for the holography analysis. In addition, we found significant table query gains by using `pycasacore`; as much as x10 speed up. A psuedocode skeleton of how the extraction is done is shown below.\n",
    "\n",
    "- `extract_holog(...)`\n",
    "    - `make_pnt_dict`(parallel axis: `antenna`) extract a subset of the pointing table data needed for the holography analysis. \n",
    "    - gather relevant spectral window information as well as odservation type information,  e.g.(MAP_ANTENNA_SURFACE#MIXED). Only keep data of a relevant type.\n",
    "    - `_extract_holog_chunk(...)`(parallel axes: ddi, scan) \n",
    "        - pull data from main table\n",
    "        - get unique scan time values\n",
    "        - `_extraxt_holog_chunk_jit` (this is jit compiled code): \n",
    "            - for each row:\n",
    "                - skip flagged rows\n",
    "                - get only relevant baselines, i.e. no auto correlation\n",
    "                - get baseline visibility data\n",
    "                - for each chan, pol:\n",
    "                    - calculate weighted sum visibilities \n",
    "                    - calculate running sum of weights\n",
    "            - for unique_time, chan, pol:\n",
    "                - calculate weighted visibilities\n",
    "    - `_extract_pointing_chunk(...)`\n",
    "        - extract directional cosines data by sampling the time values nearest the main table unique values.\n",
    "    - `_create_hack_file(...)`\n",
    "        - create hackfile data structure that contains both the visibility and the directional cosines data using common time indexing.\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eacf07a-4a1d-4724-8685-5df273ed5916",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_holog(\n",
    "    ms_name=ms_name, \n",
    "    hack_name='hack_file', \n",
    "    holog_obs_dict=holog_obs_description,\n",
    "    data_col='DATA',\n",
    "    subscan_intent='MIXED',\n",
    "    parallel=True,\n",
    "    overwrite=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98426afc-3428-422a-9fd6-37d010599b08",
   "metadata": {},
   "source": [
    "The output of `extract_holog(...)` is `hackfile` containing the extract holography information for each (ddi, scan, ant) as well as relevant meta data used later for gridding. The format of the `hackfile` on disk is a directory structure ordered as `hackfile/ddi/scan/antenna/` with an `xarray.Dataset()` at the end.\n",
    "\n",
    "The directory structure and `xarray.Dataset()` format are shown below for the example data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2116cb6b-a96e-4ed2-af66-45df8a7dc4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_hack_directory_struct(name='hack_file.holog.zarr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc03a224-6e38-4c55-8a9e-7c5baf854a58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hack, ant_data_dict = load_hack_file(\"{root}/{hack}\".format(root=os.getcwd(), hack='hack_file.holog.zarr'), dask_load=True, load_pnt_dict=False, ant_id=27)\n",
    "print_hack_file(hack=hack)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4666c77a-ce0d-4169-bc2c-691c3bb05219",
   "metadata": {},
   "source": [
    "In addition to producing the `hackfile` and antenna based dictionary is also produced which is indexed according to antenna/ddi/scan. This allows us to more easily access the data for antenna based gridding in Dask. An example for antenna-27 is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4f559e-d281-4a83-addc-555fee6a272e",
   "metadata": {},
   "outputs": [],
   "source": [
    "time = hack[0][2][26].time.values\n",
    "l = hack[0][2][26].DIRECTIONAL_COSINES[:, 0]\n",
    "m = hack[0][2][26].DIRECTIONAL_COSINES[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aaadd76-54cf-4dec-b298-ba4e38fd393f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=2, ncols=1)\n",
    "\n",
    "ax[0].scatter(l, m)\n",
    "ax[0].set_xlabel('DIRECTIONAL COSINE(L)')\n",
    "ax[0].set_ylabel('DIRECTIONAL COSINE(M)')\n",
    "\n",
    "ax[1].scatter(time, l, label='L')\n",
    "ax[1].scatter(time, m, label='M')\n",
    "\n",
    "ax[1].set_xlabel('time')\n",
    "ax[1].set_ylabel('DIRECTIONAL COSINES(L, M)')\n",
    "\n",
    "ax[1].legend(bbox_to_anchor=(1.02, 1.0), loc='upper left', borderaxespad=0.)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25aad5d3-e82e-41cd-9045-8b3bd9ca7ec3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from astrohack._utils._io import _read_dimensions_meta_data\n",
    "\n",
    "meta_data = _read_dimensions_meta_data(hack_file='hack_file.holog.zarr', ddi=0, ant_id=3)\n",
    "meta_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ec1bd7-cf3f-4aed-9a54-73a09eb0a0a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "holog(hack_file='hack_file.holog.zarr', padding_factor=250, parallel=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f4124e-9c6e-43d9-a30c-15d0d31eeea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ant_grid_data = _open_holog('hack_file.image.zarr', ddi=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0760a960-be40-49bb-b670-c857211eeacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ant_grid_data[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a401b0f7-7db4-471d-9efe-2598b4f3a885",
   "metadata": {},
   "outputs": [],
   "source": [
    "hack, ant_data_dict = load_hack_file(\"{root}/{hack}\".format(root=os.getcwd(), hack='hack_file.holog.zarr'), dask_load=True, load_pnt_dict=False, ant_id=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1a4a94-2d65-45db-ba81-390567b64a66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "grid = ant_grid_data[3].GRID.values.mean(axis=0)[0, 0, ...]\n",
    "l = ant_grid_data[3].l.values\n",
    "m = ant_grid_data[3].m.values\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "beam = plt.imshow(np.abs(grid), extent=[l.min(), l.max(), m.min(), m.max()], cmap='plasma')\n",
    "fig.colorbar(beam, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e57017-6ea5-4871-8c05-b9971897ecf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "aperture = ant_grid_data[3].APERTURE.values.mean(axis=0)[0, 0, ...]\n",
    "u = ant_grid_data[3].u.values\n",
    "v = ant_grid_data[3].v.values\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "image = plt.imshow(np.abs(aperture), extent=[u.min(), u.max(), v.min(), v.max()])\n",
    "fig.colorbar(image, ax=ax)\n",
    "\n",
    "circle = patches.Circle((0,0), 6, fill=False, color='white', alpha=0.7, linewidth=1.2)\n",
    "ax.add_patch(circle)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
